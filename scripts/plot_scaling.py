import os
import re
from math import log
from typing import Dict, Tuple

import jax.numpy as jnp
import matplotlib.pyplot as plt

from diffbank.bank import Bank
from diffbank.noise import Sn_LIGOI
from diffbank.utils import get_m1_m2_sampler
from diffbank.waveforms.threePN_simple import Psi, amp

plt.style.use("../plot_style.mplstyle")

# scatter kwargs
kwargs_s = dict(marker="X", c="C2", s=25, label="Stochastic")
kwargs_r = dict(c="C0", s=25, label="Random")
kwargs_r_est = dict(c="none", edgecolor="C1", s=25, label="Random est. (const. $q$)")
kwargs_s_est = dict(
    marker="X", c="none", edgecolor="C3", s=25, label="Stochastic est. (const. $q$)"
)


"""
Plots scaling properties of the 3.5PN-2D bank.

The requisite banks and data files are generated by running the following
scripts:
    - job-threePN-est-p.sh: estimates the covering probability `p`.
    - job-threePN-scaling.sh: generates banks with a range of different `mm`
      and `eta` values.

Generates the following plots:
    - figures/threePN-n_templates-scaling.pdf
    - figures/threePN-time-scaling.pdf

To reproduce the plots:

    >>> python plot_scaling.py

"""


def parse_ps() -> Dict[float, Tuple[float, float]]:
    """
    Parses output from job-threePN-est-p.sh.

    Returns
        Dict mapping `mm` to an MC estimate of the covering probability `p` and
        associated error `p_err`.
    """
    with open("../scripts/threePN-p.txt", "r") as f:
        lines = f.readlines()

    ps = {}
    for i in range(len(lines) // 2):
        mm = float(re.search("mm=(\d\.\d*)", lines[2 * i]).group(1))  # type: ignore

        match = re.search("p = (\d\.\d*) \+\/\- (\d\.\d*)", lines[2 * i + 1])  # type: ignore
        p = float(match.group(1))  # type: ignore
        p_err = float(match.group(2))  # type: ignore

        ps[mm] = (p, p_err)

    return ps


PS = parse_ps()
FS = jnp.linspace(20.0, 2000.0, 1000)
M_RANGE = (1.4, 5.0)
sampler = get_m1_m2_sampler(M_RANGE, M_RANGE)
ETA_REF = 0.9
MM_REF = 0.9
MMS = [0.95, 0.90, 0.85, 0.80, 0.75]
ETAS = [0.975, 0.95, 0.925, 0.900, 0.875, 0.850]


def cr_pred(p, nr, n_eff=1000):
    cr = n_eff * (1 - (1 - p) ** nr) / p
    return cr


def cs_pred(p, ns, n_eff=1000):
    cr = cr_pred(p, ns, n_eff)
    rejection_cost = (1 - p) ** (1 - ns) * (ns * p + (1 - p) ** ns - 1) / p ** 2
    return cr + rejection_cost


def predict_ns():
    n_ests, n_est_errs = {}, {}

    for mm in MMS:
        p, p_err = PS[mm]
        n_ests[(mm, ETA_REF)] = log(1 - ETA_REF) / log(1 - p)
        n_est_errs[(mm, ETA_REF)] = (
            log(1 - ETA_REF) / ((1 - p) * log(1 - p) ** 2) * p_err
        )

    for eta in ETAS:
        p, p_err = PS[MM_REF]
        n_ests[(MM_REF, eta)] = log(1 - eta) / log(1 - p)
        n_est_errs[(MM_REF, eta)] = log(1 - eta) / ((1 - p) * log(1 - p) ** 2) * p_err

    return n_ests, n_est_errs


def load_ns():
    ns, ns_s = {}, {}

    # Varying mm
    for seed, mm in enumerate(MMS, 5):
        # Random
        path = os.path.join(
            "../scripts/threePN-banks-scaling",
            f"3pn-random-{seed}-mm={mm}-eta_star={ETA_REF}-n_eff=1000.npz",
        )
        ns[(mm, ETA_REF)] = Bank.load(path, amp, Psi, Sn_LIGOI, sampler).n_templates
        # Stochastic
        path = os.path.join(
            "../scripts/threePN-banks-scaling",
            f"3pn-stochastic-{seed + 5}-mm={mm}-eta_star={ETA_REF}-n_eff=1000.npz",
        )
        ns_s[(mm, ETA_REF)] = Bank.load(path, amp, Psi, Sn_LIGOI, sampler).n_templates

    # Varying eta
    for seed, eta in enumerate(ETAS, 15):
        # Random
        path = os.path.join(
            "../scripts/threePN-banks-scaling",
            f"3pn-random-{seed}-mm={MM_REF}-eta_star={eta}-n_eff=1000.npz",
        )
        ns[(MM_REF, eta)] = Bank.load(path, amp, Psi, Sn_LIGOI, sampler).n_templates
        # Stochastic
        path = os.path.join(
            "../scripts/threePN-banks-scaling",
            f"3pn-stochastic-{seed + 6}-mm={MM_REF}-eta_star={eta}-n_eff=1000.npz",
        )
        ns_s[(MM_REF, eta)] = Bank.load(path, amp, Psi, Sn_LIGOI, sampler).n_templates

    return ns, ns_s


def load_runtimes():
    runtimes = {}
    filenames = os.listdir("../scripts/threePN-outputs-scaling/")

    # Parse tqdm output to get timing information
    for fn in filenames:
        kind = fn.split("-")[1]
        mm = float(re.search("mm=(\d*\.\d*)-", fn).group(1))  # type: ignore
        eta = float(re.search("eta_star=(\d*\.\d*)\.txt", fn).group(1))  # type: ignore

        with open(os.path.join("../scripts/threePN-outputs-scaling", fn)) as f:
            raw = f.read()
            last_pbar = raw.split("\n")[-4]

            # Convert to runtime [s]
            search_result = re.search("\[(.*)<", last_pbar)  # type: ignore
            if search_result is not None:
                raw_time = search_result.group(1)
            else:
                raw_time = re.search("\[(.*?),", last_pbar).group(1)  # type: ignore
            raw_time = raw_time.split(":")
            assert len(raw_time) <= 3
            time = sum([float(rt) * 60 ** i for i, rt in enumerate(reversed(raw_time))])

        runtimes[(kind, mm, eta)] = time

    return runtimes


def plot_n_templates_scaling(axs):
    ns, ns_s = load_ns()
    n_ests = predict_ns()[0]

    ax = axs[0]
    ax.scatter(MMS, [ns[(mm, ETA_REF)] for mm in MMS], **kwargs_r)
    ax.scatter(MMS, [n_ests[(mm, ETA_REF)] for mm in MMS], **kwargs_r_est)
    ax.scatter(MMS, [ns_s[(mm, ETA_REF)] for mm in MMS], **kwargs_s)

    ax = axs[1]
    ax.scatter(ETAS, [ns[(MM_REF, eta)] for eta in ETAS], **kwargs_r)
    ax.scatter(ETAS, [n_ests[(MM_REF, eta)] for eta in ETAS], **kwargs_r_est)
    ax.scatter(ETAS, [ns_s[(MM_REF, eta)] for eta in ETAS], **kwargs_s)
    ax.set_ylim(0, 2100)


def plot_time_scaling(axs):
    runtimes = load_runtimes()
    ns, ns_s = load_ns()

    # mm scaling
    mms = jnp.array(MMS[::-1])
    p_ests = jnp.array([PS[mm][0] for mm in mms])
    # eta scaling
    etas = jnp.array(ETAS[::-1])
    p_est_ref = PS[MM_REF][0]

    ax = axs[0]
    c_ss = jnp.array([runtimes[("stochastic", mm, ETA_REF)] for mm in mms])
    c_rs = jnp.array([runtimes[("random", mm, ETA_REF)] for mm in mms])
    nr_arr = jnp.array([ns[(mm, ETA_REF)] for mm in mms])
    ns_arr = jnp.array([ns_s[(mm, ETA_REF)] for mm in mms])
    ax.scatter(mms, c_rs, **kwargs_r)
    ax.scatter(mms, c_ss, **kwargs_s)
    c_rs_pred = cr_pred(p_ests, nr_arr)
    c_ss_pred = cs_pred(p_ests, ns_arr)
    ax.scatter(mms, c_rs_pred * c_rs[0] / c_rs_pred[0], **kwargs_r_est)
    ax.scatter(mms, c_ss_pred * c_ss[0] / c_ss_pred[0], **kwargs_s_est)

    ax = axs[1]
    c_ss = jnp.array([runtimes[("stochastic", MM_REF, eta)] for eta in etas])
    c_rs = jnp.array([runtimes[("random", MM_REF, eta)] for eta in etas])
    nr_arr = jnp.array([ns[(MM_REF, eta)] for eta in etas])
    ns_arr = jnp.array([ns_s[(MM_REF, eta)] for eta in etas])
    ax.scatter(etas, c_rs, **kwargs_r)
    ax.scatter(etas, c_ss, **kwargs_s)
    c_rs_pred = cr_pred(p_est_ref, nr_arr)
    c_ss_pred = cs_pred(p_est_ref, ns_arr)
    ax.scatter(etas, c_rs_pred * c_rs[0] / c_rs_pred[0], **kwargs_r_est)
    ax.scatter(etas, c_ss_pred * c_ss[0] / c_ss_pred[0], **kwargs_s_est)

    ax.set_yscale("log")


def run():
    fig, axes = plt.subplots(2, 2, sharey="row", figsize=(10, 6))

    plot_n_templates_scaling([axes[0, 0], axes[0, 1]])
    plot_time_scaling([axes[1, 0], axes[1, 1]])

    axes[1, 0].set_xlabel(r"$\mathrm{m}_\ast = 1 - \mathrm{m}_{\mathrm{mis},\ast}$")
    axes[1, 1].set_xlabel(r"$\eta$")
    axes[0, 0].set_ylabel(r"$N_T$")
    axes[1, 0].set_ylabel(r"$C$ [arb.]")
    axes[0, 0].set_title(r"$\eta = %g$" % ETA_REF)
    axes[0, 1].set_title(
        r"$\mathrm{m}_\ast = 1 - \mathrm{m}_{\mathrm{mis},\ast} = %g$" % MM_REF
    )

    # Customize legend
    ax = axes[1, 0]
    handles, labels = ax.get_legend_handles_labels()
    axes[0, 0].legend(handles, labels, loc="upper left", fontsize=14)

    fig.tight_layout()
    fig.savefig("figures/scaling.pdf")


if __name__ == "__main__":
    run()
